{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "np.random.seed(1337)  # for reproducibility\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution1D, MaxPooling1D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transIP(ip):\n",
    "    tmp = ip.split(\".\")\n",
    "    res = \"\"\n",
    "    for str in tmp:\n",
    "        if len(str) == 1:\n",
    "            str = \"00\" + str\n",
    "        else :\n",
    "            if len(str) == 2:\n",
    "                str = \"0\" + str\n",
    "        res += str\n",
    "    return int(res)/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set parameters:\n",
    "max_features = 900000\n",
    "maxlen = 4\n",
    "batch_size = 32\n",
    "embedding_dims = 100\n",
    "nb_filter = 250\n",
    "filter_length = 3\n",
    "hidden_dims = 250\n",
    "nb_epoch = 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501 train sequences\n",
      "101 test sequences\n",
      "[0, 51173, 71126]\n",
      "Pad sequences (samples x time)\n",
      "X_train shape: (501, 4)\n",
      "X_test shape: (101, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test  = []\n",
    "y_test  = []\n",
    "\n",
    "counter = 0;\n",
    "data = open(\"csv/output.csv\", \"r\")\n",
    "for line in data:\n",
    "    tmp = line.split(',')\n",
    "    #print(tmp[0])\n",
    "    tmp[0] = int(float(tmp[0]) * 100)\n",
    "    #print(tmp[0])\n",
    "    tmp[1] = transIP(tmp[1])\n",
    "    tmp[2] = transIP(tmp[2])\n",
    "    x_train.append(tmp[0:3])\n",
    "    y_train.append(1)\n",
    "    counter += 1\n",
    "    if(counter > 500):break\n",
    "counter = 0\n",
    "for line in data:\n",
    "    tmp = line.split(',')\n",
    "    tmp[0] = int(float(tmp[0]) * 100)\n",
    "    tmp[1] = transIP(tmp[1])\n",
    "    tmp[2] = transIP(tmp[2])\n",
    "    x_test.append(tmp[0:3])\n",
    "    y_test.append(1)\n",
    "    counter += 1\n",
    "    if(counter > 100):break\n",
    "        \n",
    "        \n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n",
    "print(x_train[1])\n",
    "\n",
    "print(\"Pad sequences (samples x time)\")\n",
    "X_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     0 51173 71126]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train on 501 samples, validate on 101 samples\n",
      "Epoch 1/3\n",
      "501/501 [==============================] - 17s - loss: 0.4746 - acc: 0.9880 - val_loss: 0.1762 - val_acc: 1.0000\n",
      "Epoch 2/3\n",
      "501/501 [==============================] - 16s - loss: 0.0696 - acc: 1.0000 - val_loss: 0.0197 - val_acc: 1.0000\n",
      "Epoch 3/3\n",
      "501/501 [==============================] - 17s - loss: 0.0110 - acc: 1.0000 - val_loss: 0.0054 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7dc362f4d0>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "\n",
    "# we start off with an efficient embedding layer which maps\n",
    "# our vocab indices into embedding_dims dimensions\n",
    "model.add(Embedding(max_features, embedding_dims, input_length=maxlen))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# we add a Convolution1D, which will learn nb_filter\n",
    "# word group filters of size filter_length:\n",
    "model.add(Convolution1D(nb_filter=nb_filter,\n",
    "                        filter_length=filter_length,\n",
    "                        border_mode=\"valid\",\n",
    "                        activation=\"relu\",\n",
    "                        subsample_length=1))\n",
    "# we use standard max pooling (halving the output of the previous layer):\n",
    "model.add(MaxPooling1D(pool_length=2))\n",
    "\n",
    "# We flatten the output of the conv layer, so that we can add a vanilla dense layer:\n",
    "model.add(Flatten())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', class_mode=\"binary\")\n",
    "model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, show_accuracy=True, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
